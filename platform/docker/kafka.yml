# If you need to persist data in the event of a container going down, uncomment volumes and make sure that
# kafka container user has the read and write permission
#   sudo chown -R 1000:1000 ./platform/kafka
version: "3.9"

services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.1
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "2181:2181"
#    volumes:
#      - ../kafka/vol1/zk-data:/var/lib/zookeeper/data
#      - ../kafka/vol2/zk-txn-logs:/var/lib/zookeeper/log
    networks:
      backend:
        aliases:
          - "zookeeper"
  kafka:
    image: confluentinc/cp-kafka:7.3.1
    container_name: kafka
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: INTERNAL://:9092,EXTERNAL_SAME_HOST://:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL_SAME_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
#    volumes:
#      - ../kafka/vol3/kafka-data:/var/lib/kafka/data
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
    networks:
      backend:
        aliases:
          - "kafka"

  kafdrop:
    image: obsidiandynamics/kafdrop:3.30.0
    container_name: kafdrop
    restart: "no"
    ports:
      - "9000:9000"
    environment:
      KAFKA_BROKERCONNECT: kafka:9092
      JVM_OPTS: "-Xms16M -Xmx48M -Xss180K -XX:-TieredCompilation -XX:+UseStringDeduplication -noverify"
    depends_on:
      - "kafka"
    networks:
      backend:
        aliases:
          - "kafka"

networks:
  backend:
    name: backend
    driver: bridge